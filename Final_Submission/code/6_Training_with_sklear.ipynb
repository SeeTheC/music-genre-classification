{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas;\n",
    "import numpy as np;\n",
    "import ast;\n",
    "import sklearn.tree as tree;\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSVFile(file):\n",
    "    data=pandas.read_csv(file,\",\",header=0, na_values='?', skipinitialspace=True);\n",
    "    return data;\n",
    "    pass;\n",
    "def readTrainData(dataset):    \n",
    "    return dataset.ix[:,6:], dataset.ix[:,4:5].astype(int),dataset.ix[:,5:6];\n",
    "    pass;\n",
    "\n",
    "def readTestData(dataset):    \n",
    "    return dataset.ix[:,6:], dataset.ix[:,4:5].astype(int),dataset.ix[:,5:6];\n",
    "    pass;\n",
    "\n",
    "def normalizePhi(unNormalizedPhi,last_col_bias=False):    \n",
    "    #assuming last column as bias column\n",
    "    no_of_column=len(unNormalizedPhi[0]);\n",
    "    phi=np.array(unNormalizedPhi);\n",
    "    std=phi.std(0);\n",
    "    mean=phi.mean(0);    \n",
    "    #std[no_of_column-1]=1;\n",
    "    #mean[no_of_column-1]=0;\n",
    "    #phi_normalize=(phi-mean)/std;    \n",
    "    \n",
    "    max_vector=phi.max(axis=0)\n",
    "    phi_normalize=phi/max_vector;    \n",
    "    \n",
    "    return phi_normalize;\n",
    "    pass;\n",
    "\n",
    "def categoryToNumber(dataset,categoryList):\n",
    "    for c in categoryList:\n",
    "        if (c in dataset):            \n",
    "            dataset[c]=pandas.get_dummies(dataset[c]).values.argmax(1);        \n",
    "    return dataset;\n",
    "    pass;\n",
    "    \n",
    "\n",
    "def handleCategoryData(dataset,categoryList):    \n",
    "        return categoryToNumber(dataset,categoryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1037a166f783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "OneVsRestClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir=\"data/\"\n",
    "trainFile=dir+\"train.csv\";\n",
    "testFile=dir+\"test.csv\";\n",
    "trained_dataset=readCSVFile(trainFile);\n",
    "test_dataset=readCSVFile(testFile);\n",
    "trained_data,trained_y,trained_y_vector=readTrainData(trained_dataset);\n",
    "test_data,test_y,test_y_vector=readTestData(test_dataset);\n",
    "\n",
    "mtx_train =trained_data.as_matrix(columns=None)\n",
    "mtx_train_y  =trained_y.as_matrix(columns=None)\n",
    "mtx_trained_y_vector=trained_y_vector.as_matrix(columns=None);\n",
    "\n",
    "mtx_train_norm=normalizePhi(mtx_train);\n",
    "mtx_train_y=np.array(list((e[0] for e in mtx_train_y)));\n",
    "mtx_trained_y_vector=np.array(list((ast.literal_eval(e[0]) for e in mtx_trained_y_vector)));\n",
    "\n",
    "mtx_test=test_data.as_matrix(columns=None);\n",
    "mtx_test_y=test_y.as_matrix(columns=None);\n",
    "mtx_test_y_vector=test_y_vector.as_matrix(columns=None);\n",
    "\n",
    "mtx_test_norm=normalizePhi(mtx_test);\n",
    "mtx_test_y=np.array(list((e[0] for e in mtx_test_y)));\n",
    "mtx_test_y_vector=np.array(list((ast.literal_eval(e[0]) for e in mtx_test_y_vector)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 5 5 5 5 5\n",
      " 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 6 1 5 5 5 5 5 5 5 5 5 5 6 5 5 1 5 5 1 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 6 1 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 1 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 6 5 5 5 5 5 5 5 5 5 6 5 5 1 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 1 5 5 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1\n",
      " 5 5 5 5 5 5 5 5 5 5 1 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 5 1 6 6 5 5\n",
      " 5 5 5 5 5 5 6 1 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 1 5 5 5 5 6 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 1 5 5 1 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6\n",
      " 5 5 5 5 5 5 5 5 1 5 5 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 6 6 5 5 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 5 6\n",
      " 5 5 5 5 1 5 5 1 5 5 5 5 5 5 5 6 1 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 5\n",
      " 5 5 1 5 5 5 5 5 5 1 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 6 5 1 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 6 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 6 5 5 6 5 5 1 5 5 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 6 5 5 5 6 5 5 5]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#trainedModel=OneVsRestClassifier(LinearSVC()).fit(mtx_train, mtx_train_y);\n",
    "trainedModel=LinearSVC().fit(mtx_train, mtx_train_y);\n",
    "y_predict=trainedModel.predict(mtx_train);\n",
    "print(y_predict);\n",
    "print(\"done\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 1 6 1 6 2 1 1 1 1 4 6 6 1 6 6 3 2 1 1 6 1 1 6 6 2 1 6 1 2 2 3 1 1\n",
      " 1 1 6 1 3 1 6 2 1 1 1 9 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 2 1 2 1\n",
      " 2 2 6 2 6 1 3 1 1 1 1 3 3 1 2 1 1 2 1 4 1 2 1 1 9 1 6 1 2 1 1 1 1 6 6 1 1\n",
      " 6 1 1 1 1 3 1 1 1 1 1 1 6 6 1 1 1 2 1 1 2 1 1 6 1 1 3 1 2 6 3 1 2 1 1 1 1\n",
      " 1 1 6 1 1 1 1 2 1 1 1 1 3 2 1 1 1 1 1 1 1 1 1 1 3 2 1 1 1 6 4 1 1 1 1 6 1\n",
      " 1 6 6 1 6 1 1 1 1 6 1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "y_predict=trainedModel.predict(mtx_test);\n",
    "print(y_predict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trained Misclassified Points</th>\n",
       "      <th>Trained Accuracy</th>\n",
       "      <th>Test Misclassified Points</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>215</td>\n",
       "      <td>73</td>\n",
       "      <td>95</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>63</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Neighbors</th>\n",
       "      <td>401</td>\n",
       "      <td>49</td>\n",
       "      <td>145</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>85</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>385</td>\n",
       "      <td>51</td>\n",
       "      <td>105</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector</th>\n",
       "      <td>631</td>\n",
       "      <td>21</td>\n",
       "      <td>156</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli NB</th>\n",
       "      <td>638</td>\n",
       "      <td>20</td>\n",
       "      <td>154</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian NB</th>\n",
       "      <td>462</td>\n",
       "      <td>42</td>\n",
       "      <td>113</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>539</td>\n",
       "      <td>32</td>\n",
       "      <td>146</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Trained Misclassified Points  Trained Accuracy  \\\n",
       "Decision Tree                                 215                73   \n",
       "Random Forest                                  63                92   \n",
       "K-Neighbors                                   401                49   \n",
       "Gradient Boosting                               1                99   \n",
       "Logistic Regression                           385                51   \n",
       "Support Vector                                631                21   \n",
       "Bernoulli NB                                  638                20   \n",
       "Gaussian NB                                   462                42   \n",
       "Adaboost                                      539                32   \n",
       "\n",
       "                     Test Misclassified Points  Test Accuracy  \n",
       "Decision Tree                               95             52  \n",
       "Random Forest                               80             60  \n",
       "K-Neighbors                                145             27  \n",
       "Gradient Boosting                           85             57  \n",
       "Logistic Regression                        105             47  \n",
       "Support Vector                             156             22  \n",
       "Bernoulli NB                               154             23  \n",
       "Gaussian NB                                113             43  \n",
       "Adaboost                                   146             27  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trained_data\n",
    "y = np.ravel(trained_y)\n",
    "y_test=np.ravel(test_y);\n",
    "\n",
    "index = [\"Decision Tree\", \"Random Forest\", \"K-Neighbors\", \"Gradient Boosting\",\n",
    "         \"Logistic Regression\", \"Support Vector\", \"Bernoulli NB\", \"Gaussian NB\",\"Adaboost\"]\n",
    "columns = [\"Trained Misclassified Points\", \"Trained Accuracy\", \"Test Misclassified Points\", \"Test Accuracy\",]\n",
    "modelComparision = pandas.DataFrame(index=index, columns=columns)\n",
    "\n",
    "dtc = 0, DecisionTreeClassifier(min_samples_split=20)\n",
    "rfc = 1, RandomForestClassifier(min_samples_split=10)\n",
    "knn = 2, KNeighborsClassifier()\n",
    "gbc = 3, GradientBoostingClassifier(max_depth=3)\n",
    "lgr = 4, LogisticRegression(max_iter=300)\n",
    "svc = 5, LinearSVC(max_iter=4000)\n",
    "bnb = 6, BernoulliNB()\n",
    "gnb = 7, GaussianNB()\n",
    "ada = 8, AdaBoostClassifier()\n",
    "\n",
    "tr_size=len(x.index);\n",
    "tt_size=len(y_test);\n",
    "for i in lgr, gnb, bnb, dtc, svc, knn, rfc, gbc, ada:    \n",
    "    model=i[1].fit(x, y);\n",
    "    y_pred = model.predict(x)\n",
    "    tr_misclassifedPoints = (y_pred != y).sum()  \n",
    "    tr_accuracy = ((tr_size - tr_misclassifedPoints)*100) / tr_size;\n",
    "    \n",
    "    y_pred = model.predict(test_data)\n",
    "    tt_misclassifedPoints = (y_pred != y_test).sum()  \n",
    "    tt_accuracy = ((tt_size - tt_misclassifedPoints)*100) / tt_size;\n",
    "    if(i[0]==0):\n",
    "        tree.export_graphviz(model,out_file='tree.dot');        \n",
    "    #print(misclassifedPoints,\":\",size - misclassifedPoints,':',accuracy);   \n",
    "    modelComparision.ix[i[0]] = [tr_misclassifedPoints, tr_accuracy, tt_misclassifedPoints, tt_accuracy,];\n",
    "    \n",
    "print(\"Done\");\n",
    "modelComparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n",
      "[[0 1 1 ..., 0 0 1]\n",
      " [0 1 1 ..., 0 0 1]\n",
      " [0 1 1 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 1 ..., 0 0 1]\n",
      " [0 1 1 ..., 0 0 1]\n",
      " [0 1 1 ..., 0 0 1]]\n",
      "(0, ':', 100)\n",
      "[[0 1 1 ..., 0 0 1]\n",
      " [0 1 1 ..., 0 0 1]\n",
      " [0 1 1 ..., 0 0 1]\n",
      " ..., \n",
      " [0 1 1 ..., 0 0 1]\n",
      " [0 1 1 ..., 0 0 1]\n",
      " [0 1 1 ..., 0 0 1]]\n",
      "(0, ':', 100)\n"
     ]
    }
   ],
   "source": [
    "x=mtx_train_norm;\n",
    "y=mtx_trained_y_vector;\n",
    "model = MLPClassifier(solver='sgd', alpha=1e-7, activation=\"logistic\",hidden_layer_sizes=(2, 100),\n",
    "                        max_iter=10000,learning_rate_init=0.00000001, learning_rate='constant',\n",
    "                        random_state=1);\n",
    "model.fit(x,y);\n",
    "tt_size=len(y);\n",
    "print(\"Training done\");\n",
    "y_pred = model.predict(x)\n",
    "print(y_pred);\n",
    "tt_misclassifedPoints = (y_pred != y).sum()  \n",
    "tt_accuracy = ((tt_size - tt_misclassifedPoints)*100) / tt_size;\n",
    "print(misclassifedPoints,\":\",accuracy);\n",
    "\n",
    "x=mtx_test_norm;\n",
    "y=mtx_test_y_vector;\n",
    "y_pred = model.predict(x)\n",
    "size=len(y);\n",
    "print(y_pred);\n",
    "tt_misclassifedPoints = (y_pred != y).sum()  \n",
    "tt_accuracy = ((size - tt_misclassifedPoints)*100) / size;\n",
    "print(misclassifedPoints,\":\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
